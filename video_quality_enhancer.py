#!/usr/bin/env python3
"""
VIDEO QUALITY ENHANCER
Advanced improvements for ALL video generation formats.
Addresses low engagement (avg 60 views, 0.1 likes).
"""

import os
import subprocess
import json
from typing import Dict, List, Optional, Tuple
import random


class VideoQualityEnhancer:
    """
    Enhances video quality across all formats with proven techniques.
    """

    def __init__(self):
        self.ffmpeg = self._find_ffmpeg()

    def _find_ffmpeg(self) -> str:
        """Find FFmpeg binary"""
        import shutil
        paths = ['/opt/homebrew/bin/ffmpeg', '/usr/local/bin/ffmpeg', 'ffmpeg']
        for path in paths:
            if shutil.which(path) or os.path.exists(path):
                return path
        return 'ffmpeg'

    # =========================================================================
    # IMPROVEMENT 1: HOOK-BASED OPENINGS (First 3 Seconds = 80% Retention)
    # =========================================================================

    def generate_hook_script(self, topic: str, format_type: str = "ranking") -> str:
        """
        Generate attention-grabbing hook for first 3 seconds.

        Research shows 80% of viewers decide in first 3 seconds.

        Args:
            topic: Video topic
            format_type: "ranking", "standard", or "trending"

        Returns: Hook script (2-3 seconds narration)
        """
        hooks = {
            'ranking': [
                f"You WON'T believe what's number 1!",
                f"Number 5 will SHOCK you!",
                f"This countdown will blow your mind!",
                f"Wait until you see what tops this list!",
                f"I can't believe {self._extract_key_word(topic)} actually exists!"
            ],
            'standard': [
                f"This will change everything you know about {self._extract_key_word(topic)}!",
                f"Nobody talks about this side of {self._extract_key_word(topic)}!",
                f"The truth about {self._extract_key_word(topic)} is insane!",
                f"Everything you know about {self._extract_key_word(topic)} is wrong!"
            ],
            'trending': [
                f"This is BLOWING UP right now!",
                f"Everyone's talking about this!",
                f"You need to see this before it goes viral!",
                f"This is breaking the internet TODAY!"
            ]
        }

        format_hooks = hooks.get(format_type, hooks['standard'])
        return random.choice(format_hooks)

    def _extract_key_word(self, topic: str) -> str:
        """Extract key word from topic for dynamic hooks"""
        # Remove common words
        stop_words = {'the', 'a', 'an', 'of', 'on', 'in', 'at', 'to', 'for'}
        words = [w for w in topic.lower().split() if w not in stop_words and len(w) > 3]
        return words[0] if words else "this"

    # =========================================================================
    # IMPROVEMENT 2: DYNAMIC TEXT OVERLAYS (5x Higher Retention)
    # =========================================================================

    def create_dynamic_text_overlay(
        self,
        text: str,
        rank: Optional[int] = None,
        style: str = "modern"
    ) -> str:
        """
        Create FFmpeg drawtext filter for dynamic animated text.

        Args:
            text: Text to display
            rank: Ranking number (if applicable)
            style: "modern", "bold", "neon"

        Returns: FFmpeg filter string
        """
        # Font settings by style
        styles = {
            'modern': {
                'fontfile': '/System/Library/Fonts/Helvetica.ttc',
                'fontcolor': 'white',
                'fontsize': '60',
                'box': '1',
                'boxcolor': 'black@0.7',
                'boxborderw': '10'
            },
            'bold': {
                'fontfile': '/System/Library/Fonts/Helvetica.ttc',
                'fontcolor': '#FFD700',  # Gold
                'fontsize': '70',
                'box': '1',
                'boxcolor': 'black@0.8',
                'boxborderw': '15',
                'shadowcolor': 'black',
                'shadowx': '5',
                'shadowy': '5'
            },
            'neon': {
                'fontfile': '/System/Library/Fonts/Helvetica.ttc',
                'fontcolor': '#00FFFF',  # Cyan
                'fontsize': '65',
                'box': '1',
                'boxcolor': '#FF00FF@0.6',  # Magenta
                'boxborderw': '12'
            }
        }

        style_config = styles.get(style, styles['modern'])

        # Escape text for FFmpeg
        text_escaped = text.replace("'", "\\'").replace(":", "\\:")

        # Build drawtext filter with animation
        filter_parts = [
            f"drawtext=text='{text_escaped}'",
            f"fontfile='{style_config['fontfile']}'",
            f"fontsize={style_config['fontsize']}",
            f"fontcolor={style_config['fontcolor']}",
            f"x=(w-text_w)/2",  # Center horizontally
            f"y=h*0.15",  # Top 15% of screen
            f"box={style_config['box']}",
            f"boxcolor={style_config['boxcolor']}",
            f"boxborderw={style_config['boxborderw']}",
            # Fade in animation
            f"alpha='if(lt(t,0.3),t/0.3,if(lt(t,8),1,if(lt(t,8.5),(8.5-t)/0.5,0)))'"
        ]

        # Add rank badge if applicable
        if rank:
            rank_filter = f",drawtext=text='#{rank}':fontfile='{style_config['fontfile']}':fontsize=80:fontcolor='#FFD700':x=w*0.05:y=h*0.05:box=1:boxcolor='black@0.8':boxborderw=10"
            filter_parts.append(rank_filter[1:])  # Remove leading comma

        return ":".join(filter_parts)

    # =========================================================================
    # IMPROVEMENT 3: SMART CLIP SELECTION (Avoid Boring Stock Footage)
    # =========================================================================

    def generate_smart_search_queries(self, topic: str, context: str = "") -> List[str]:
        """
        Generate multiple search queries for better clip variety.

        Args:
            topic: Main topic
            context: Additional context

        Returns: List of search queries (primary + fallbacks)
        """
        # Primary query
        queries = [topic]

        # Extract keywords and create variations
        words = topic.lower().split()

        # Add specific variations
        if "ranking" in topic.lower() or "top" in topic.lower():
            # For ranking videos, focus on ACTION not static images
            action_words = ["in action", "footage", "moving", "dynamic", "fast"]
            queries.extend([f"{topic} {action}" for action in action_words])

        # Add emotional keywords for better engagement
        emotional_keywords = ["epic", "intense", "breathtaking", "stunning", "amazing"]
        queries.extend([f"{emotional_keywords[i % len(emotional_keywords)]} {topic}"
                       for i in range(2)])

        # Add time-of-day variations for visual variety
        tod_keywords = ["sunset", "golden hour", "dramatic lighting"]
        queries.append(f"{topic} {random.choice(tod_keywords)}")

        return queries[:5]  # Return top 5 queries

    # =========================================================================
    # IMPROVEMENT 4: ADVANCED AUDIO MIXING (Professional Sound)
    # =========================================================================

    def create_professional_audio_mix(
        self,
        voiceover_path: str,
        music_path: str,
        output_path: str,
        voice_volume: float = 1.0,
        music_volume: float = 0.08,  # Lower than before for clarity
        enable_compressor: bool = True,
        enable_eq: bool = True
    ) -> bool:
        """
        Create professional audio mix with compression and EQ.

        Args:
            voiceover_path: Path to voiceover file
            music_path: Path to background music
            output_path: Output path
            voice_volume: Voiceover volume multiplier
            music_volume: Music volume (low for background)
            enable_compressor: Add compression for consistent volume
            enable_eq: Add EQ for clarity

        Returns: Success status
        """
        try:
            # Build audio filter chain
            filters = []

            # Voice processing
            voice_chain = f"[0:a]volume={voice_volume}"

            if enable_eq:
                # EQ to enhance voice clarity (boost mid-range)
                voice_chain += ",equalizer=f=2000:width_type=h:width=1000:g=3"

            if enable_compressor:
                # Compression for consistent volume
                voice_chain += ",acompressor=threshold=-20dB:ratio=4:attack=5:release=50"

            voice_chain += "[voice]"
            filters.append(voice_chain)

            # Music processing with ducking
            music_chain = f"[1:a]volume={music_volume}[music]"
            filters.append(music_chain)

            # Sidechain compression (music ducks when voice present)
            duck_chain = "[music][voice]sidechaincompress=threshold=-30dB:ratio=4:attack=50:release=300[music_ducked]"
            filters.append(duck_chain)

            # Final mix
            mix_chain = "[voice][music_ducked]amix=inputs=2:duration=shortest:normalize=0"
            filters.append(mix_chain)

            filter_complex = ";".join(filters)

            cmd = [
                self.ffmpeg, '-y',
                '-i', voiceover_path,
                '-i', music_path,
                '-filter_complex', filter_complex,
                '-c:a', 'aac',
                '-b:a', '192k',
                output_path
            ]

            result = subprocess.run(cmd, capture_output=True, timeout=60)
            return result.returncode == 0

        except Exception as e:
            print(f"Audio mixing error: {e}")
            return False

    # =========================================================================
    # IMPROVEMENT 5: MOTION EFFECTS (Prevent Static Footage)
    # =========================================================================

    def add_motion_effects(
        self,
        input_path: str,
        output_path: str,
        effect_type: str = "zoom_pan"
    ) -> bool:
        """
        Add motion effects to static footage.

        Args:
            input_path: Input video
            output_path: Output video
            effect_type: "zoom_pan", "ken_burns", "shake"

        Returns: Success status
        """
        try:
            effects = {
                'zoom_pan': "zoompan=z='min(zoom+0.0015,1.5)':d=125:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'",
                'ken_burns': "zoompan=z='if(lte(zoom,1.0),1.5,max(1.001,zoom-0.0015))':d=125:x='iw/2-(iw/zoom/2)':y='ih/2-(ih/zoom/2)'",
                'shake': "crop=iw-100:ih-100:50+50*sin(t*4):50+50*cos(t*3)"  # Subtle shake
            }

            effect = effects.get(effect_type, effects['zoom_pan'])

            cmd = [
                self.ffmpeg, '-y',
                '-i', input_path,
                '-vf', f"{effect},scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2",
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-crf', '23',
                '-c:a', 'copy',
                output_path
            ]

            result = subprocess.run(cmd, capture_output=True, timeout=120)
            return result.returncode == 0

        except Exception as e:
            print(f"Motion effects error: {e}")
            return False

    # =========================================================================
    # IMPROVEMENT 6: SMART TRANSITIONS (Smooth, Not Jarring)
    # =========================================================================

    def create_transition_video(
        self,
        clip1_path: str,
        clip2_path: str,
        output_path: str,
        transition_type: str = "crossfade",
        duration: float = 0.5
    ) -> bool:
        """
        Create smooth transition between two clips.

        Args:
            clip1_path: First clip
            clip2_path: Second clip
            output_path: Output path
            transition_type: "crossfade", "slide", "wipe"
            duration: Transition duration in seconds

        Returns: Success status
        """
        try:
            transitions = {
                'crossfade': f"xfade=transition=fade:duration={duration}:offset=0",
                'slide': f"xfade=transition=slideleft:duration={duration}:offset=0",
                'wipe': f"xfade=transition=wiperight:duration={duration}:offset=0",
                'zoom': f"xfade=transition=zoomin:duration={duration}:offset=0"
            }

            transition = transitions.get(transition_type, transitions['crossfade'])

            cmd = [
                self.ffmpeg, '-y',
                '-i', clip1_path,
                '-i', clip2_path,
                '-filter_complex', f"[0:v][1:v]{transition}[v]",
                '-map', '[v]',
                '-c:v', 'libx264',
                '-preset', 'fast',
                output_path
            ]

            result = subprocess.run(cmd, capture_output=True, timeout=120)
            return result.returncode == 0

        except Exception as e:
            print(f"Transition error: {e}")
            return False

    # =========================================================================
    # IMPROVEMENT 7: ENGAGEMENT OPTIMIZATION (Call-to-Actions)
    # =========================================================================

    def add_engagement_prompts(
        self,
        video_path: str,
        output_path: str,
        prompts: List[Dict] = None
    ) -> bool:
        """
        Add engagement prompts (Like, Subscribe, Comment) at strategic points.

        Args:
            video_path: Input video
            output_path: Output video
            prompts: List of {time, text, position} dicts

        Returns: Success status
        """
        if prompts is None:
            # Default prompts at key moments
            prompts = [
                {'time': 3, 'text': 'üëç LIKE if you agree!', 'position': 'bottom'},
                {'time': 20, 'text': 'üí¨ Comment your favorite!', 'position': 'bottom'},
                {'time': 40, 'text': 'üîî Subscribe for more!', 'position': 'bottom'}
            ]

        try:
            # Build drawtext filters for each prompt
            filters = []
            for i, prompt in enumerate(prompts):
                time = prompt['time']
                text = prompt['text'].replace("'", "\\'").replace(":", "\\:")

                # Position
                if prompt['position'] == 'bottom':
                    y_pos = 'h*0.85'
                elif prompt['position'] == 'top':
                    y_pos = 'h*0.10'
                else:
                    y_pos = 'h*0.50'

                # Fade in/out (show for 3 seconds)
                fade_in = time
                fade_out = time + 3

                filter_str = f"drawtext=text='{text}':fontfile=/System/Library/Fonts/Helvetica.ttc:fontsize=40:fontcolor=white:x=(w-text_w)/2:y={y_pos}:box=1:boxcolor=black@0.8:boxborderw=8:enable='between(t,{fade_in},{fade_out})'"

                if i == 0:
                    filters.append(filter_str)
                else:
                    filters.append(f"[tmp{i}];[tmp{i}]{filter_str}[tmp{i+1}]")

            # Combine filters
            if len(filters) == 1:
                filter_complex = filters[0]
            else:
                filter_complex = filters[0] + "[tmp1];" + ";".join(filters[1:])

            cmd = [
                self.ffmpeg, '-y',
                '-i', video_path,
                '-vf', filter_complex,
                '-c:v', 'libx264',
                '-preset', 'fast',
                '-c:a', 'copy',
                output_path
            ]

            result = subprocess.run(cmd, capture_output=True, timeout=120)
            return result.returncode == 0

        except Exception as e:
            print(f"Engagement prompts error: {e}")
            return False


# Testing
if __name__ == "__main__":
    print("=" * 70)
    print("üé¨ VIDEO QUALITY ENHANCER")
    print("=" * 70)

    enhancer = VideoQualityEnhancer()

    # Test 1: Hook generation
    print("\n1Ô∏è‚É£ Hook Generation:")
    hooks = [
        enhancer.generate_hook_script("Deadliest Roller Coasters", "ranking"),
        enhancer.generate_hook_script("Climate Change Facts", "standard"),
        enhancer.generate_hook_script("NBA Highlights", "trending")
    ]
    for i, hook in enumerate(hooks, 1):
        print(f"   Hook {i}: {hook}")

    # Test 2: Smart search queries
    print("\n2Ô∏è‚É£ Smart Search Queries:")
    queries = enhancer.generate_smart_search_queries("Roller Coaster", "extreme")
    for i, query in enumerate(queries, 1):
        print(f"   Query {i}: {query}")

    # Test 3: Dynamic text overlay
    print("\n3Ô∏è‚É£ Dynamic Text Overlay:")
    overlay = enhancer.create_dynamic_text_overlay("MOST EXTREME LOCATION", rank=5, style="bold")
    print(f"   Filter: {overlay[:100]}...")

    print("\n‚úÖ All quality enhancements ready!")
    print("\n" + "=" * 70)
